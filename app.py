import os
import re
import time
import streamlit as st
from urllib.parse import urlparse, parse_qs
from operator import itemgetter

# --- LangChain and other necessary imports ---
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableLambda, RunnableParallel, RunnablePassthrough
from langchain_core.messages import HumanMessage, AIMessage
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled

# --- Import Google Generative AI LLM wrapper ---
from langchain_google_genai import ChatGoogleGenerativeAI

# --- CONSTANTS ---
SESSION_TIMEOUT_SECONDS = 900 # 15 minutes
LANGUAGES = {
    "English": "en",
    "Hindi": "hi",
    "Spanish": "es",
    "French": "fr",
    "German": "de",
    "Japanese": "ja",
}

# --- Helper Function to Extract YouTube Video ID (No changes) ---
def get_video_id(url: str) -> str | None:
    """
    Extracts the YouTube video ID from a YouTube URL.
    Handles standard, short, and embed URLs.
    """
    if not url:
        return None
    regex = r"(?:youtube\.com\/(?:[^\/]+\/.+\/|(?:v|e(?:mbed)?)\/|.*[?&]v=)|youtu\.be\/)([a-zA-Z0-9_-]{11})"
    match = re.search(regex, url)
    if match:
        return match.group(1)
    return None

# --- Core RAG Functions ---

@st.cache_data(show_spinner="Fetching transcript...")
def get_transcript(video_id: str, language: str) -> str | None:
    """
    Fetches and formats the transcript for a given video ID and language.
    """
    try:
        fetched_transcript_object = YouTubeTranscriptApi().fetch(video_id, languages=[language])
        transcript_list = fetched_transcript_object.to_raw_data()
        transcript = " ".join(chunk["text"] for chunk in transcript_list)
        return transcript
        
    except TranscriptsDisabled:
        st.error(f"Transcripts are disabled for this video (ID: {video_id}). Please try another video.")
        return None
    except Exception as e:
        st.error(f"Could not retrieve transcript for language '{language}'. Error: {e}")
        try:
            available_transcripts = YouTubeTranscriptApi.list_transcripts(video_id)
            available_langs = [t.language_code for t in available_transcripts]
            st.warning(f"This video has transcripts available for: {', '.join(available_langs)}")
        except Exception:
            pass
        return None

def format_chat_history(messages):
    """Formats chat history from Streamlit's message format to LangChain's format."""
    history = []
    # Loop through all messages except the last one, which is the current user prompt
    for msg in messages[:-1]:
        if msg["role"] == "user":
            history.append(HumanMessage(content=msg["content"]))
        else:
            history.append(AIMessage(content=msg["content"]))
    return history

def create_rag_chain(_transcript: str):
    """Creates a RAG chain with OpenAI embeddings + Google Gemini LLM."""
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = text_splitter.create_documents([_transcript])

    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=st.secrets["OPENAI_API_KEY"]
    )

    vector_store = FAISS.from_documents(docs, embeddings)
    retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={"k": 4})

    rag_template = """
You are a helpful assistant that answers questions based ONLY on the provided video transcript context.
Your tone should be conversational and helpful.

If the context is insufficient to answer the question, you MUST respond with ONLY the following exact sentence:
"I am sorry, but the transcript does not contain information to answer that question."

CONTEXT:
{context}

QUESTION: {question}
"""
    prompt = ChatPromptTemplate.from_messages([
        ("system", rag_template),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{question}")
    ])

    llm = ChatGoogleGenerativeAI(
        model="gemini-1.5-flash",
        temperature=0.3,
        google_api_key=st.secrets["GOOGLE_API_KEY"]
    )

    def format_docs(retrieved_docs):
        return "\n\n".join(doc.page_content for doc in retrieved_docs)

    rag_chain = (
        {
            "context": itemgetter("question") | retriever | RunnableLambda(format_docs),
            "question": itemgetter("question"),
            "chat_history": itemgetter("chat_history")
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    return rag_chain

def reset_session():
    """Resets the Streamlit session state to start with a new video."""
    st.session_state.messages = [
        {"role": "assistant", "content": "Hi! I'm ready for a new video. Provide a URL to get started."}
    ]
    st.session_state.rag_chain = None
    st.session_state.video_id = None
    st.session_state.trigger_fallback = False
    # This line is safe here because this function is only used as an on_click callback,
    # which runs BEFORE the rest of the script reruns.
    if 'youtube_url_input' in st.session_state:
        st.session_state.youtube_url_input = ""
    get_transcript.clear()

# --- Streamlit UI ---

st.set_page_config(page_title="YT-CHAT-AI", page_icon="ðŸ“º", layout="wide")

if 'last_interaction_time' in st.session_state and \
   (time.time() - st.session_state.last_interaction_time > SESSION_TIMEOUT_SECONDS):
    st.warning(f"Session timed out due to inactivity. Please start over.")
    reset_session()
    st.rerun() # Force a rerun after reset

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Hi! I'm ready for a new video. Provide a URL to get started."}
    ]
    st.session_state.rag_chain = None
    st.session_state.video_id = None
    st.session_state.trigger_fallback = False

if 'welcome_message_shown' not in st.session_state:
    st.toast("Welcome to Youtube Video Agent! ðŸ‘‹", icon="ðŸŽ‰")
    time.sleep(0.5)
    st.toast("Clear your doubts without watching the whole video.", icon="ðŸš€")
    st.session_state.welcome_message_shown = True

st.markdown("""
<div style="
    background: linear-gradient(90deg, #4F80C9, #7A60B3);
    padding: 1.5rem;
    border-radius: 10px;
    color: white;
    text-align: center;
    margin-bottom: 20px;
">
<h1 style="color:white; font-size: 2.5rem; font-weight: bold; margin: 0;">YT-CHAT-AI</h1>
<p style="margin: 5px 0 0 0; font-size: 1.1rem;">Your Intelligent YouTube Video Assistant</p>
</div>
""", unsafe_allow_html=True)

with st.expander("ðŸ”— Get Started: Enter Video Details Here", expanded=True):
    youtube_url = st.text_input("YouTube URL", key="youtube_url_input", placeholder="e.g., https://www.youtube.com/watch?v=dQw4w9WgXcQ")

    selected_lang_name = st.selectbox(
        "Select Transcript Language",
        options=list(LANGUAGES.keys()),
        key="language_select"
    )

    if st.button("Start Chatting", type="primary"):
        if youtube_url:
            video_id = get_video_id(youtube_url)
            if video_id:
                # +++ THE FIX IS HERE +++
                # Instead of calling reset_session(), we do a "soft reset"
                # to prepare for the new video without clearing the URL input field.
                st.session_state.rag_chain = None
                st.session_state.video_id = video_id
                st.session_state.trigger_fallback = False
                get_transcript.clear() 
                # +++ END OF FIX +++
                
                language_code = LANGUAGES[selected_lang_name]
                transcript = get_transcript(video_id, language_code)
                if transcript:
                    st.session_state.rag_chain = create_rag_chain(transcript)
                    st.session_state.messages = [
                        {"role": "assistant", "content": f"I'm ready! Ask me anything about the video."}
                    ]
                    st.success("Assistant is ready! You can now ask questions below.")
                    st.rerun() # Rerun to reflect the new state immediately
                else:
                    st.session_state.video_id = None
            else:
                st.error("Invalid YouTube URL. Please enter a valid one.")
        else:
            st.warning("Please provide a YouTube URL.")

    if st.session_state.get('video_id') and st.session_state.get('rag_chain'):
        st.divider()
        st.success(f"Video Loaded Successfully!")
        if st.session_state.get('youtube_url_input'):
             st.video(st.session_state.youtube_url_input)
        
        # This button uses the full reset_session as a callback, which is correct.
        st.button("Chat with Another Video", on_click=reset_session)

st.divider()

# --- Chat History Display ---
for message in st.session_state.messages:
    with st.chat_message(message["role"], avatar="âœ¨" if message["role"] == "assistant" else "ðŸ‘¤"):
        with st.container(border=True):
            st.markdown(message["content"])

# --- Chat Input and Response Handling ---
if prompt := st.chat_input("Ask a question about the video..."):
    if st.session_state.rag_chain is None:
        st.error("Please set up a video in the 'Get Started' section above first.")
    else:
        st.session_state.last_interaction_time = time.time()
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user", avatar="ðŸ‘¤"):
            with st.container(border=True):
                st.markdown(prompt)

        with st.chat_message("assistant", avatar="âœ¨"):
            with st.container(border=True):
                with st.spinner("Thinking..."):
                    try:
                        response = ""
                        chat_history = format_chat_history(st.session_state.messages)
                        
                        if st.session_state.get('trigger_fallback', False):
                            st.info("Answering from general knowledge as requested...", icon="ðŸ§ ")
                            
                            general_llm = ChatGoogleGenerativeAI(
                                model="gemini-1.5-flash",
                                temperature=0.7,
                                google_api_key=st.secrets["GOOGLE_API_KEY"]
                            )
                            general_prompt = ChatPromptTemplate.from_messages([
                                ("system", "You are a helpful conversational assistant. Answer the user's question based on the chat history and your general knowledge."),
                                MessagesPlaceholder(variable_name="chat_history"),
                                ("human", "{question}")
                            ])
                            general_chain = general_prompt | general_llm | StrOutputParser()
                            
                            response = general_chain.invoke({
                                "question": prompt,
                                "chat_history": chat_history
                            })
                            st.session_state.trigger_fallback = False
                        
                        else:
                            response = st.session_state.rag_chain.invoke({
                                "question": prompt,
                                "chat_history": chat_history
                            })
                            
                            fail_message = "I am sorry, but the transcript does not contain information to answer that question."
                            if response.strip() == fail_message:
                                st.session_state.trigger_fallback = True
                                response += "\n\nIf you'd like me to try answering this from my general knowledge, please ask again."
                        
                        st.markdown(response)
                        st.session_state.messages.append({"role": "assistant", "content": response})

                    except Exception as e:
                        error_message = f"An error occurred: {e}"
                        st.error(error_message)
                        st.session_state.messages.append({"role": "assistant", "content": error_message})